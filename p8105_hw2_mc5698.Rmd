---
title: "p8105_hw2_mc5698.Rmd"
output:
  pdf_document: default
  html_document: default
date: "2024-09-27"
---

#Question 1
```{r}
#loading necessary packages
library(tidyverse)
library(readxl)
```

```{r}
#clean the dataset
nyc_t = 
  read_csv(
    "/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10,route11, entry, vending, entrance_type, ada) |> 
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE))
```

The dataset contains `r names(nyc_t)`. For the data cleaning, I removed unnecessary columns and convert the entry variable from character to a logical variable by using `case_match` function. The dimension of the resulting dataset is `r dim(nyc_t)`. These data are mostly tidy but we could pivot different route columns into one variable. 
```{r}
distinct_stations=
  nyc_t|>
  distinct(station_name,line)
nrow(distinct_stations)
```
```{r}
ada_stations=
  nyc_t|>
  filter(ada==TRUE)|>
  distinct(station_name, line)

nrow(ada_stations)
```
```{r}
no_vending=
  nyc_t |>
  filter(vending == "NO") |>
  pull(entry)
 
proportion_entry= mean(no_vending)
proportion_entry
```

There are 465 distinct stations. 84 stations are ADA compliant.The proportion of station entrances/exits without vending allow entrance is `proportion_entry`. 

```{r}
transfrom_ent=
  nyc_t |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route")

A_stations=
    transfrom_ent |>
    filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
  

ada_stations =
  transfrom_ent |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()

```
There are `r n_distinct(A_stations$station_name)` distinct stations serve the A train and `r n_distinct(ada_stations$station_name)`stations serve the A train and ADA compliant.

#Question 2
```{r}
#clean the datasets
mr_trash_wheel = 
  readxl::read_excel("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/202409TrashWheelCollectionData.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  filter(!is.na(Dumpster)) |> 
  mutate(Sports_Balls = as.integer(round(`Sports Balls`)),
         Year = as.character(Year),
         Trash_Wheel = "Mr. Trash Wheel")

professor_trash_wheel = 
  readxl::read_excel("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/202409TrashWheelCollectionData.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> 
  filter(!is.na(Dumpster)) |> 
  mutate(Year = as.character(Year),
         Trash_Wheel = "Professor Trash Wheel")

gwynnda_trash_wheel = 
  readxl::read_excel("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/202409TrashWheelCollectionData.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> 
  filter(!is.na(Dumpster)) |> 
  mutate(Year = as.character(Year),
         Trash_Wheel = "Gwynnda Trash Wheel")

combined_data = 
  bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)
combined_data
```
By reading and cleaning the datasets, I combined the three datasets from `Mr. Trash Wheel`, `Professor Trash Wheel` and `Gwynnda Trash Wheel`. There are `r nrow(combined_data)` observations in the combined dataset. This dataset includes key variables such as`Dumpster`, which shows the the number of dumpster filled by trash, and `Cigarette Butts` which means the number of cigarette they collected. It also includes the specific time of the trash such as `Year`, `Date`, `Month` and `Trash_Wheel` indicates different trash types correspond to the different trash wheel. Moreover, it provides the detailed volumn and types for each trash wheel. 

```{r}
tw_professor = 
  combined_data |> 
  filter(Trash_Wheel == "Professor Trash Wheel") |> 
  summarise(total_weight = sum(`Weight (tons)`, na.rm = TRUE))
```

```{r}
cb_gwynnda_june2022 = 
  combined_data |> 
  filter(Trash_Wheel == "Gwynnda Trash Wheel", Year == "2022", Month == "June") |> 
  summarise(total_cig_butts = sum(`Cigarette Butts`, na.rm = TRUE))
```
The total weight of trash collected by Professor Trash Wheel wad  `r pull(tw_professor)`. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r pull(cb_gwynnda_june2022)`.

#Question 3
```{r}
#read and clean the datasets
bakers = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/bakers.csv") |>
  mutate(source = "bakers")

bakes = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/bakes.csv") |>
  mutate(source = "bakes")

results = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/results.csv", skip = 2) |>
  rename(Series = series,
         Episode = episode, 
         Baker = baker, 
         Technical = technical, 
         Result = result) |>
  filter(!is.na(Series)) |>
  mutate(Series = as.numeric(Series),
         Episode = as.numeric(Episode))

viewers = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/viewers.csv") |>
  pivot_longer(cols = starts_with("Series"), 
               names_to = "Series", 
               names_prefix = "Series ", 
               values_to = "Viewership") |>
  mutate(Series = as.numeric(Series))
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
