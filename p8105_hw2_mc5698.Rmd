---
title: "p8105_hw2_mc5698.Rmd"
output: github_document
  
date: "2024-09-27"
---

#Question 1
```{r}
#loading necessary packages
library(tidyverse)
library(readxl)
```

```{r}
#clean the dataset
nyc_t = 
  read_csv(
    "/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10,route11, entry, vending, entrance_type, ada) |> 
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE))
```

The dataset contains `r names(nyc_t)`. For the data cleaning, I removed unnecessary columns and convert the entry variable from character to a logical variable by using `case_match` function. The dimension of the resulting dataset is `r dim(nyc_t)`. These data are mostly tidy but we could pivot different route columns into one variable. 
```{r}
distinct_stations=
  nyc_t|>
  distinct(station_name,line)
nrow(distinct_stations)
```
```{r}
ada_stations=
  nyc_t|>
  filter(ada==TRUE)|>
  distinct(station_name, line)

nrow(ada_stations)
```
```{r}
no_vending=
  nyc_t |>
  filter(vending == "NO") |>
  pull(entry)
 
proportion_entry= mean(no_vending)
proportion_entry
```

There are 465 distinct stations. 84 stations are ADA compliant.The proportion of station entrances/exits without vending allow entrance is 0.3770492. 

```{r}
transfrom_ent=
  nyc_t |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route")

A_stations=
  transfrom_ent|>
  filter(route == "A") |> 
  distinct(station_name, line) 
  

nyc_t |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  distinct(station_name, line)



```
There are 60 distinct stations serve the A train and 17 stations serve the A train and ADA compliant.

#Question 2
```{r}
#clean the datasets
mr_trash_wheel = 
  readxl::read_excel("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/202409TrashWheelCollectionData.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  filter(!is.na(Dumpster)) |> 
  mutate(Sports_Balls = as.integer(round(`Sports Balls`)),
         Year = as.character(Year),
         Trash_Wheel = "Mr. Trash Wheel")

professor_trash_wheel = 
  readxl::read_excel("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/202409TrashWheelCollectionData.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> 
  filter(!is.na(Dumpster)) |> 
  mutate(Year = as.character(Year),
         Trash_Wheel = "Professor Trash Wheel")

gwynnda_trash_wheel = 
  readxl::read_excel("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/202409TrashWheelCollectionData.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> 
  filter(!is.na(Dumpster)) |> 
  mutate(Year = as.character(Year),
         Trash_Wheel = "Gwynnda Trash Wheel")

combined_data = 
  bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)
combined_data
```
By reading and cleaning the datasets, I combined the three datasets from `Mr. Trash Wheel`, `Professor Trash Wheel` and `Gwynnda Trash Wheel`. There are `r nrow(combined_data)` observations in the combined dataset. This dataset includes key variables such as`Dumpster`, which shows the the number of dumpster filled by trash, and `Cigarette Butts` which means the number of cigarette they collected. It also includes the specific time of the trash such as `Year`, `Date`, `Month` and `Trash_Wheel` indicates different trash types correspond to the different trash wheel. Moreover, it provides the detailed volumn and types for each trash wheel. 

```{r}
tw_professor = 
  combined_data |> 
  filter(Trash_Wheel == "Professor Trash Wheel") |> 
  summarise(total_weight = sum(`Weight (tons)`, na.rm = TRUE))
```

```{r}
cb_gwynnda_june2022 = 
  combined_data |> 
  filter(Trash_Wheel == "Gwynnda Trash Wheel", Year == "2022", Month == "June") |> 
  summarise(total_cig_butts = sum(`Cigarette Butts`, na.rm = TRUE))
```
The total weight of trash collected by Professor Trash Wheel wad  `r pull(tw_professor)`. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r pull(cb_gwynnda_june2022)`.

#Question 3
```{r}
#read and clean the datasets
bakers = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/bakers.csv") |>
  rename(Baker = `Baker Name`) |>
  mutate(source = "bakers")

bakes = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/bakes.csv") |>
  mutate(source = "bakes")

results = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/results.csv", skip = 2) |>
  rename(Series = series,
         Episode = episode, 
         Baker = baker, 
         Technical = technical, 
         Result = result) |>
  filter(!is.na(Series)) |>
  mutate(Series = as.numeric(Series),
         Episode = as.numeric(Episode))

viewers = 
  read_csv("/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/viewers.csv") |>
  pivot_longer(cols = starts_with("Series"), 
               names_to = "Series", 
               names_prefix = "Series ", 
               values_to = "Viewership") |>
  mutate(Series = as.numeric(Series))
```
```{r}
#check for completeness and correctness across datasets 
missing_bakers =
  results %>%
  anti_join(bakers, by = c("Baker", "Series"))
```

```{r}
#rename the column names and merge the datasets
results =
  results |> 
  mutate(Baker = tolower(trimws(Baker)), 
         Series = as.numeric(Series))

bakers = 
  bakers |> 
  mutate(Baker = tolower(trimws(Baker)))

bakes =
  bakes |> 
  mutate(Baker = tolower(trimws(Baker)), 
         Series = as.numeric(Series))

final_datasets=
  results|>
  left_join(bakers, by = c("Baker", "Series")) |>
  left_join(bakes, by = c("Baker", "Series", "Episode"))%>%
  left_join(viewers, by = "Series")%>%
  arrange(Series, Episode.x) %>%
  select(Series, Episode.x, Baker, Baker_Age = `Baker Age`, Baker_Occupation = `Baker Occupation`, Technical, Result, Viewership, Signature_Bake = `Signature Bake`, Showstopper = `Show Stopper`, everything())

head(final_datasets)
```
```{r}
write_csv(final_datasets, "/Users/nicolechen/Downloads/p8105_hw2_mc5698/dataset/gbb_datasets/final_dataset.csv")
```
For this project, I cleaned and organized data from `bakers.csv`, `bakes.csv`, `results.csv`, and `viewers.csv.` Firstly, I renamed the `Baker Name` column to `Baker` in the `bakers.csv` file to make it easier to match with other datasets. Then, I noticed that the baker names had different formats, so I used a function to convert all the names to lowercase and remove extra spaces.I also transformed the `Series` and `Episode`· columns to numeric for easier merging. For `viewers.csv`, I reshaped the data from wide to long format to align with the other files.
After checking for missing bakers between the files, I merged the datasets step by step: first, results with `bakers`, then with `bakes`, and finally with `viewers.` I organized the data by series and episode to make it more readable. The final dataset contains all relevant information, including bakers' details, results, and viewership.

```{r}
#Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10
star_baker =
  final_datasets %>%
  filter(Series >= 5 & Series <= 10, Result %in% c("STAR BAKER", "WINNER")) %>%
  select(Series, Episode = Episode.x, Baker, Result) %>%
  arrange(Series, Episode)
star_baker
```
From the table, I found that some people such as Richard become star bakers or winners in multiple episodes, which might make their overall success predictable.
```{r}
#import, clean, tidy, and organize the viewership data
head(viewers, 10)

average_viewership =
  viewers %>%
  group_by(Series) %>%
  summarise(Average_Viewership = 
              mean(Viewership, na.rm = TRUE))

season_1 =
  average_viewership %>%
  filter(Series == 1) %>%
  pull(Average_Viewership)

season_5 =
  average_viewership %>%
  filter(Series == 5) %>%
  pull(Average_Viewership)
```
The average viewership in Season 1 is  `r season_1`, and the average viewership in Season 5 is approximately `r season_5`, showing the growth in the show’s popularity.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
